\documentclass{article}
\usepackage{listings}
\usepackage{graphicx} % Required for inserting images
\usepackage{color}
\usepackage[a4paper, total={6.5in, 10in}]{geometry}
\usepackage{enumitem}

\lstnewenvironment{C}
  {\lstset{language=C}} 
%Add your addition parameters as required like showstringspaces , line numbering , 
% frames , etc.seperated by a comma as shown in the CPP  environment 
  {}
\lstnewenvironment{CPP}
  {\lstset{language=C++,basicstyle=\ttfamily\small,frame=none}}
  {}
\lstnewenvironment{Java}
  {\lstset{language=Java}}
  {}
\lstnewenvironment{Python}
  {\lstset{language=Python}}
  {}

% \title{\huge TP3 Report \\ Artificial Intelligence}
% \author{Bruno Luiz Dias Alves de Castro \\ Victor Gabriel Mendes Sündermann}
% \date{April 2023}

\begin{document}

\begin{titlepage}
\centering
{\textsc{\Large ESIEE Paris \\ ~\\ Artificial Intelligence and Cybersecurity} \par}
\vfill
{\huge\bfseries Artificial Intelligence \par}
\vspace{0.5cm}
{\LARGE Lab 3 Report \par}
\vspace{2cm}
{\Large\itshape Bruno Luiz Dias Alves de Castro \par}
{\Large\itshape Victor Gabriel Mendes Sündermann \par}
\vfill

% Bottom of the page
{\large \today\par}
\end{titlepage}

\pagebreak
\tableofcontents
\pagebreak

\section{Introduction}

In this report, we will present the results of the third project of the Artificial Intelligence course. The project consists of implementing

\section{Tests}
To run the program, we use the following command:

\hbox{}

\definecolor{light-gray}{gray}{0.95}
\begin{lstlisting}[language=bash, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
  python3 pacman_AIC.py -p ReflexAgent [-l testClassic]
\end{lstlisting}

\hbox{}

Running the command without the flag \textit{-l testClassic}, renders a version of the maze without any walls.

The first two tests ran as expected, the Pacman tries to eat all the food in the field while avoiding all the ghosts. The mai problem with both tests is that, while avoiding the ghosts, it'll stay in place most of the time, and not go after the food.

This can be improved by implementing an evaluation function, which will be developed in the next section.

\pagebreak
\section{Reflex Agent}

In this part, we were purposed to improve the \textbf{ReflexAgent} function in the \textbf{multiAgents.py} file in the project by proposing an evaluation function.

\subsection{ReflexAgent improvement}

In order to improve the \textbf{ReflexAgent}, we need a good evalution function to help the AI decide what to do next. A great evaluation function should be able to tell the agent what is the best action to take in a given state, rewarding good actions and punishing bad ones.

For our problem, we decided that a good action should be eating a food pellet, and a bad action should be getting eaten by a ghost. So, our evaluation function calculates the distance of Pacman to the food pallets and the ghosts. It then returns a score like the following:

\hbox{}

\begin{lstlisting}[language=bash, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
    return score + closestFoodScore - closestGhostScore
\end{lstlisting}

\hbox{}

We also decided on using the Manhattan distance to calculate the distance between Pacman, the ghosts and the food pellets, because it is a less computationally expensive sollution to this problem, and don't really affect the final score.

\hbox{}

Finally, the result we got is the following:

\hbox{}

\begin{lstlisting}[language=python, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
def evaluationFunction(self, currentGameState, action):

    """ VARIABLES """

    foodList = newFood.asList()

    # manhattan distance
    foodDistances = \
        [manhattanDistance(newPos, food) for food in foodList]
    ghostDistances = \
        [manhattanDistance(newPos, ghost) for ghost in newGhostsPos]

    # closest food and ghost
    closestFood = min(foodDistances) if len(foodDistances) > 0 else 0
    closestGhost = min(ghostDistances) if len(ghostDistances) > 0 else 0

    # score calculation for food and ghost
    closestFoodScore = 0 if closestFood == 0 else 1.0/closestFood
    closestGhostScore = 0 if closestGhost == 0 else 1.0/closestGhost

    score = closestFoodScore - closestGhostScore

    return successorGameState.getScore() + score
\end{lstlisting}

\subsection{Tests}

In order to test our new evaluation function, we executed the following tests:

\subsubsection{testClassic}
\label{sec:testClassic}

\textbf Command:

\begin{lstlisting}[language=bash, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
    python3 pacman_AIC.py -p ReflexAgent -l testClassic
\end{lstlisting}

\noindent\textbf Output:

\begin{lstlisting}[language=bash, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
  Pacman emerges victorious! Score: 562
  Average Score: 562.0
  Scores:        562.0
  Win Rate:      1/1 (1.00)
  Record:        Win
\end{lstlisting}

\subsubsection{mediumClassic}
\label{sec:mediumClassic}

- One ghost test run \\
~\\
\textbf Command:

\begin{lstlisting}[language=bash, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
    python3 pacman_AIC.py -p ReflexAgent -k 1
\end{lstlisting}

\noindent\textbf Output:

\begin{lstlisting}[language=bash, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
    Pacman emerges victorious! Score: 1485
    Average Score: 1485.0
    Scores:        1485.0
    Win Rate:      1/1 (1.00)
    Record:        Win
\end{lstlisting}

~\\
- Two ghosts test run \\
~\\
\textbf Command:

\begin{lstlisting}[language=bash, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
    python3 pacman_AIC.py -p ReflexAgent -k 2
\end{lstlisting}

\noindent\textbf Output:

\begin{lstlisting}[language=bash, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
    Pacman emerges victorious! Score: 1407
    Average Score: 1407.0
    Scores:        1407.0
    Win Rate:      1/1 (1.00)
    Record:        Win
\end{lstlisting}

\subsubsection{No layout 20 runs average}
\label{sec:20runs}

During this part of the testing, we ran the \textbf{ReflexAgent} 20 times on each of the 6 conbinations of the settings listed below, and calculated the average score and the win rate. The possible settings are as listed (indentified with the letters a-e):

\begin{itemize}
  \item Possible settings:
  \begin{enumerate}[label=(\alph*)]
    \item One ghost
    \item Two ghosts
    \item Random ghosts
    \item Random ghosts with fixed seed
    \item Non random ghost
  \end{enumerate}
\end{itemize}

~\\
The results obteined are shown in Table \ref{tab:reflexagent}.

\begin{table}[!ht]
  \begin{center}
  \begin{tabular}{||c||c|c|c|c|c|c||}
  \hline
  Configuration & (a, c) & (a,d) & (a, e) & (b, c) & (b,d) & (b, e) \\
  \hline\hline
  Average Score & 671.65 & 785.2 & 449.9 & 464.7 & 228.7 & -14.25 \\
  \hline\hline
  Win Rate & 14/20 (0.70) & 18/20 (0.90) & 10/20 (0.50) & 10/20 (0.50) & 6/20 (0.30) & 1/20 (0.05) \\
  \hline
  \end{tabular}
  \caption{ReflexAgent test results}
  \label{tab:reflexagent}
  \end{center}
\end{table}

\subsubsection{Results}
The \textbf{ReflexAgent} was sucessful in clearing most of the purposed tests. Especially the the ran in sections \ref{sec:testClassic} and \ref{sec:mediumClassic} (\textbf{testClassic} and \textbf{mediumClassic}), were no problem for the agent.

Things start to fall short when it comes to test in section \ref{sec:20runs}. The agent obtained decent success in the test with a single ghost, but performenced declined on tests with two ghost. The agent only cleared 6 out of 20 tests with random ghosts, and was onle able to clear a single test with non random ghosts.

\pagebreak
\section{Minimax}

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla vitae nisl nec nunc placerat lacinia.

\subsection{Minimax implementation}

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla vitae nisl nec nunc placerat lacinia.

\begin{table}[!ht]
\begin{lstlisting}[language=python, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
def MAX_VALUE(self, gameState, d):
  if d == 0 or gameState.isWin() or gameState.isLose():
      return self.evaluationFunction(gameState), Directions.STOP
  
  bestScore, bestAction = -9999, Directions.STOP

  for action in gameState.getLegalActions(0):
      successors = gameState.generateSuccessor(0, action)
      value, _ = self.MIN_VALUE(successors, d, 1)
      if value > bestScore:
          bestScore, bestAction = value, action

  return bestScore, bestAction
\end{lstlisting}
\caption{Maximizer function}
\end{table}

\begin{table}[!ht]
\begin{lstlisting}[language=python, frame=tlbr, framesep=6pt, backgroundcolor=\color{light-gray}]
def MIN_VALUE(self, gameState, d, indexAgent):
  if d == 0 or gameState.isWin() or gameState.isLose():
      return self.evaluationFunction(gameState), Directions.STOP

  bestScore, bestAction = 9999, Directions.STOP

  for action in gameState.getLegalActions(indexAgent):
      successors = gameState.generateSuccessor(indexAgent, action)
      if indexAgent == gameState.getNumAgents() - 1:
          value, _ = self.MAX_VALUE(successors, d - 1)
      else:
          value, _ = self.MIN_VALUE(successors, d, indexAgent + 1)

      if value < bestScore:
          bestScore, bestAction = value, action

  return bestScore, bestAction
\end{lstlisting}
\caption{Minimizer function}
\end{table}


\subsection{Tests}

In order to test the Minimax algorithm implemented, we ran it 20 times, using different depths, and the results are shown in the table below: \\

\begin{table}[ht]
  \begin{center}
  \begin{tabular}{||c||c|c|c||}
    \hline
    Depth & 2 & 3 & 4 \\
    \hline\hline
    Iteration & - & - & - \\
    \hline
    1 & -231 (L) & -276 (L) &  840 (W) \\
    \hline
    2 & -206 (L) & 1254 (W) &   32 (L) \\
    \hline
    3 & -244 (L) & -336 (L) & 1732 (W) \\
    \hline
    4 & -154 (L) & -263 (L) & -314 (L) \\
    \hline
    5 & 1249 (W) &  966 (W) &  311 (W) \\
    \hline
    6 & -688 (L) &  -96 (L) &  540 (L) \\
    \hline
    7 & -185 (L) & 1138 (W) &  204 (L) \\
    \hline
    8 & -203 (L) &  959 (W) &  479 (L) \\
    \hline
    9 & -239 (L) & 1531 (W) & 1171 (W) \\
    \hline
    10 & -140 (L) &  116 (L) &  -97 (L) \\
    \hline
    11 & -317 (L) & 1373 (W) &  896 (W) \\
    \hline
    12 &  178 (L) & 1039 (W) & 1218 (W) \\
    \hline
    13 & -176 (L) & -174 (L) & 1048 (W) \\
    \hline
    14 & -624 (L) & 1168 (W) &  223 (L) \\
    \hline
    15 & -180 (L) & -156 (L) &  402 (L) \\
    \hline
    16 & -238 (L) &  749 (W) & 1238 (W) \\
    \hline
    17 & -243 (L) & -267 (L) & 1202 (W) \\
    \hline
    18 &    8 (L) & 1147 (W) & 1631 (W) \\
    \hline
    19 & -368 (L) & 1319 (W) &  277 (L) \\
    \hline
    20 & -454 (L) & -272 (L) &  985 (W) \\
    \hline\hline
    Average &  -173 &  546 &  701 \\
    \hline\hline
    Best & 1249 & 1531 & 1732 \\
    \hline\hline
    Win Rate & 1/20 (0.05) & 11/20 (0.55) & 11/20 (0.55) \\
    \hline
  \end{tabular}
  \caption{Minimax test results}
  \end{center}
\end{table}

\end{document}